#!/usr/bin/env python3
"""
èŠå¤©è™•ç†å™¨
è™•ç†èˆ‡ LLM ç›¸é—œçš„è«‹æ±‚
"""

import asyncio
import logging
import requests
import re
from typing import Dict, List, Optional, Any
from datetime import datetime

logger = logging.getLogger(__name__)


class ChatHandler:
    """èŠå¤©è™•ç†å™¨"""
    
    def __init__(self, llm_config: Dict, tools_handler=None):
        self.llm_model = llm_config.get("model", "Llama-3.2-1B-Instruct-CPU")
        self.llm_endpoint = llm_config.get("endpointUrl", "http://localhost:8000/api/v1")
        self.tools_handler = tools_handler
        self.conversation_history = []
        self.max_history = 10
    
    async def process_message(self, user_message: str) -> str:
        """è™•ç†èŠå¤©æ¶ˆæ¯"""
        try:
            # æ·»åŠ åˆ°å°è©±æ­·å²
            self.conversation_history.append({
                "role": "user",
                "content": user_message
            })
            
            # ä¿æŒå°è©±æ­·å²åœ¨é™åˆ¶å…§
            if len(self.conversation_history) > self.max_history * 2:
                self.conversation_history = self.conversation_history[-self.max_history * 2:]
            
            # æº–å‚™ç³»çµ±æ¶ˆæ¯
            system_message = self._build_system_message(user_message)
            
            # èª¿ç”¨ LLM
            messages = [system_message] + self.conversation_history[-self.max_history:]
            llm_response = await self._call_llm(messages)
            
            # æª¢æŸ¥æ˜¯å¦éœ€è¦ä½¿ç”¨å·¥å…·
            tool_result = await self._check_and_use_tools(user_message)
            
            # çµ„åˆæœ€çµ‚éŸ¿æ‡‰
            final_response = llm_response
            if tool_result:
                final_response += f"\n\n{tool_result}"
            
            # æ·»åŠ åŠ©æ‰‹å›æ‡‰åˆ°æ­·å²
            self.conversation_history.append({
                "role": "assistant",
                "content": final_response
            })
            
            return final_response
            
        except Exception as e:
            logger.error(f"Error processing chat message: {e}")
            return f"æŠ±æ­‰ï¼Œè™•ç†æ‚¨çš„æ¶ˆæ¯æ™‚ç™¼ç”ŸéŒ¯èª¤: {str(e)}"
    
    def _build_system_message(self, user_message: str) -> Dict:
        """æ§‹å»ºç³»çµ±æ¶ˆæ¯"""
        context = ""
        
        # æ·»åŠ å¯ç”¨å·¥å…·ä¿¡æ¯
        if self.tools_handler:
            tools_context = self.tools_handler.get_context_info()
            if tools_context:
                context += tools_context + "\n\n"
        
        return {
            "role": "system",
            "content": f"""ä½ æ˜¯ä¸€å€‹å‹å–„çš„æ¡Œé¢åŠ©æ‰‹ï¼Œå¯ä»¥å¹«åŠ©ç”¨æˆ¶ç®¡ç†ç€è¦½å™¨æ¨™ç±¤é å’Œé€²è¡Œè¨ˆç®—ã€‚
è«‹ç”¨ç¹é«”ä¸­æ–‡ç°¡æ½”å›ç­”ï¼Œä¸è¶…é30å€‹å­—ã€‚

ç•¶å‰ä¸Šä¸‹æ–‡ä¿¡æ¯:
{context}

ç”¨æˆ¶è¼¸å…¥: {user_message}"""
        }
    
    async def _call_llm(self, messages: List[Dict]) -> str:
        """èª¿ç”¨ LLM API"""
        try:
            payload = {
                "model": self.llm_model,
                "messages": messages,
                "max_tokens": 100,
                "temperature": 0.7
            }
            
            response = requests.post(
                f"{self.llm_endpoint}/chat/completions",
                json=payload,
                headers={"Content-Type": "application/json"},
                timeout=30
            )
            
            response.raise_for_status()
            result = response.json()
            
            return result["choices"][0]["message"]["content"].strip()
            
        except Exception as e:
            logger.error(f"LLM API call failed: {e}")
            return "æŠ±æ­‰ï¼ŒLLM æœå‹™æš«æ™‚ç„¡æ³•ä½¿ç”¨ ğŸ˜…"
    
    def call_llm_stream(self, user_message: str):
        """æµå¼èª¿ç”¨ LLMï¼ˆç°¡åŒ–ç‰ˆæœ¬ï¼‰"""
        try:
            # æ·»åŠ åˆ°å°è©±æ­·å²
            self.conversation_history.append({
                "role": "user",
                "content": user_message
            })
            
            # ä¿æŒå°è©±æ­·å²åœ¨é™åˆ¶å…§
            if len(self.conversation_history) > self.max_history * 2:
                self.conversation_history = self.conversation_history[-self.max_history * 2:]
            
            # æº–å‚™ç³»çµ±æ¶ˆæ¯
            system_message = self._build_system_message(user_message)
            
            # èª¿ç”¨ LLM
            messages = [system_message] + self.conversation_history[-self.max_history:]
            response = asyncio.run(self._call_llm(messages))
            
            # æª¢æŸ¥æ˜¯å¦éœ€è¦ä½¿ç”¨å·¥å…·
            tool_result = asyncio.run(self._check_and_use_tools(user_message))
            
            # çµ„åˆæœ€çµ‚éŸ¿æ‡‰
            final_response = response
            if tool_result:
                final_response += f"\n\n{tool_result}"
            
            # æ·»åŠ åŠ©æ‰‹å›æ‡‰åˆ°æ­·å²
            self.conversation_history.append({
                "role": "assistant",
                "content": final_response
            })
            
            # æ¨¡æ“¬æµå¼è¿”å›
            words = final_response.split()
            if not words:
                yield {"content": "æŠ±æ­‰ï¼Œæˆ‘ç¾åœ¨ç„¡æ³•å›æ‡‰ ğŸ˜…", "fullResponse": "æŠ±æ­‰ï¼Œæˆ‘ç¾åœ¨ç„¡æ³•å›æ‡‰ ğŸ˜…"}
                return
                
            for i, word in enumerate(words):
                yield {
                    "content": word + (" " if i < len(words) - 1 else ""),
                    "fullResponse": " ".join(words[:i+1])
                }
                
        except Exception as e:
            logger.error(f"Stream LLM call failed: {e}")
            yield {"error": f"æŠ±æ­‰ï¼Œè™•ç†æ‚¨çš„æ¶ˆæ¯æ™‚ç™¼ç”ŸéŒ¯èª¤: {str(e)}"}
    
    async def _check_and_use_tools(self, user_message: str) -> str:
        """æª¢æŸ¥æ˜¯å¦éœ€è¦ä½¿ç”¨å·¥å…·ä¸¦åŸ·è¡Œ"""
        if not self.tools_handler:
            return ""
        
        try:
            # æª¢æŸ¥æ˜¯å¦åŒ…å«æ•¸å­¸é‹ç®—é—œéµå­—
            math_keywords = ["è¨ˆç®—", "åŠ æ³•", "æ¸›æ³•", "ä¹˜æ³•", "é™¤æ³•", "+", "-", "*", "/", "åŠ ", "æ¸›", "ä¹˜", "é™¤"]
            
            if any(keyword in user_message for keyword in math_keywords):
                # å˜—è©¦æå–æ•¸å­—
                numbers = re.findall(r'\d+(?:\.\d+)?', user_message)
                
                if len(numbers) >= 2:
                    a = float(numbers[0])
                    b = float(numbers[1])
                    
                    # æ ¹æ“šé—œéµå­—æ±ºå®šé‹ç®—é¡å‹
                    if "åŠ " in user_message or "+" in user_message:
                        return await self.tools_handler.call_tool("add", {"a": a, "b": b})
                    elif "æ¸›" in user_message or "-" in user_message:
                        return await self.tools_handler.call_tool("subtract", {"a": a, "b": b})
                    elif "ä¹˜" in user_message or "*" in user_message:
                        return await self.tools_handler.call_tool("multiply", {"a": a, "b": b})
                    elif "é™¤" in user_message or "/" in user_message:
                        return await self.tools_handler.call_tool("divide", {"a": a, "b": b})
                    else:
                        return await self.tools_handler.call_tool("add", {"a": a, "b": b})
            
            return ""
            
        except Exception as e:
            logger.error(f"Tool usage error: {e}")
            return f"å·¥å…·èª¿ç”¨éŒ¯èª¤: {str(e)}"
    
    def clear_history(self):
        """æ¸…é™¤å°è©±æ­·å²"""
        self.conversation_history.clear()
        logger.info("Conversation history cleared")
    
    def get_history(self) -> List[Dict]:
        """ç²å–å°è©±æ­·å²"""
        return self.conversation_history.copy()